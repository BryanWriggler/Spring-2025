\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[margin = 2.54cm]{geometry}
\usepackage[most]{tcolorbox}

\newtcolorbox{myBox}[3]{
arc=5mm,
lower separated=false,
fonttitle=\bfseries,
%colbacktitle=green!10,
%coltitle=green!50!black,
enhanced,
attach boxed title to top left={xshift=0.5cm,
        yshift=-2mm},
colframe=blue!50!black,
colback=blue!10
}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\linespread{1.2}

\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{question}{Question}

\title{Math CS 122B HW2}
\author{Zih-Yu Hsieh}

\begin{document}
\maketitle

\section*{1}
\begin{myBox}[]{}
    \begin{question}
        Stein and Shakarchi Chap. 6 Exercise 7:

        The \textbf{Beta function} is defined for $Re(\alpha)>0$ and $Re(\beta)>0$ by
        $$B(\alpha,\beta)=\int_{0}^{1}(1-t)^{\alpha-1}t^{\beta-1}dt$$
        \begin{itemize}
            \item[(a)] Prove that 
            $$B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$$
            \item[(b)] Show that
            $$B(\alpha,\beta)=\int_{0}^{\infty}\frac{u^{\alpha-1}}{(1+u)^{\alpha+\beta}}du$$
        \end{itemize}
    \end{question}
\end{myBox}

\textbf{Pf:}

\begin{itemize}
    \item[(a)] First, we'll consider $\Gamma(\alpha)\Gamma(\beta)$:
    $$\Gamma(\alpha)\Gamma(\beta)=\int_{0}^{\infty}t^{\alpha-1}e^{-t}dt\int_{0}^{\infty}s^{\beta-1}e^{-s}ds=\int_{0}^{\infty}\int_{0}^{\infty}t^{\alpha-1}s^{\beta-1}e^{-s-t}dsdt$$
    If we consider the change of variable $f:(0,1)\times (0,\infty)\rightarrow (0,\infty)\times (0,\infty)$ by $f(r,u)=(ur,u(1-r))=(s,t)$, since this is a differentiable function, and its derivative is given by:
    $$Df = \begin{pmatrix}
        \frac{\partial f_1}{\partial r}&\frac{\partial f_1}{\partial u}\\
        \frac{\partial f_2}{\partial r}&\frac{\partial f_2}{\partial u}
    \end{pmatrix}=\begin{pmatrix}
        \frac{\partial}{\partial r}(ur)&\frac{\partial}{\partial u}(ur)\\
        \frac{\partial}{\partial r}(u(1-r))&\frac{\partial}{\partial u}(u(1-r))
    \end{pmatrix}=\begin{pmatrix}
        u&r\\
        -u&(1-r) 
    \end{pmatrix}$$
    $$\frac{\partial (s,t)}{\partial (r,u)}=\begin{vmatrix}
        u&r\\-u&(1-r)
    \end{vmatrix}=u(1-r)-(-u)r=u$$
    Then, the above integral can be given as:
    $$\Gamma(\alpha)\Gamma(\beta)=\int_{0}^{\infty}\int_{0}^{\infty}t^{\alpha-1}s^{\beta-1}e^{-s-t}dsdt = \int_{0}^{\infty}\int_{0}^{1}(u(1-r))^{\alpha-1}(ur)^{\beta-1}e^{-(ur+u(1-r))}\left|\frac{\partial (s,t)}{\partial (r,u)}\right|drdu$$
    $$=\int_{0}^{\infty}\int_{0}^{1}u^{\alpha+\beta-2}e^{-u}\cdot (1-r)^{\alpha-1}r^{\beta-1}udrdu=\int_{0}^{\infty}u^{\alpha+\beta-1}e^{-u}\cdot (1-r)^{\alpha-1}r^{\beta-1}drdu$$
    $$=\int_{0}^{\infty}u^{\alpha+\beta-1}e^{-u}du\cdot\int_{0}^{1}(1-r)^{\alpha-1}r^{\beta-1}dr = \Gamma(\alpha+\beta)\cdot B(\alpha,\beta)$$
    Hence, we can rewrite the above equality to be as follow:
    $$\Gamma(\alpha)\Gamma(\beta)=\Gamma(\alpha+\beta)\cdot B(\alpha,\beta),\quad B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$$
    
    \hfil 

    \item[(b)] Consider the following expression:
    $$\int_{0}^{\infty}\frac{u^{\alpha-1}}{(1+u)^{\alpha+\beta}}du$$
    First, if we do the substitution $(1+u)=e^t$, $du=e^tdt$, which $u=0\implies e^t=1,\ t=0$, and $\lim_{t\rightarrow\infty}e^t=\infty$, so $\lim_{t\rightarrow\infty}u=\infty$. Then, the integral can be rewrite as:
    $$\int_{0}^{\infty}\frac{u^{\alpha-1}}{(1+u)^{\alpha+\beta}}du=\int_{0}^{\infty}\frac{(e^t-1)^{\alpha-1}}{(e^t)^{\alpha+\beta}}e^tdt=\int_{0}^{\infty}((1-e^{-t})e^t)^{\alpha-1}(e^{-t})^{\alpha+\beta}\cdot e^tdt$$
    $$=\int_{0}^{\infty}(1-e^{-t})^{\alpha-1}\cdot (e^{t})^{\alpha-1}\cdot (e^{t})^{-\alpha}\cdot (e^t)^{-\beta}\cdot e^tdt = \int_{0}^{\infty}(1-e^{-t})^{\alpha-1}(e^{-t})^\beta dt$$
    Then, for the above expression, if we do the second substitution $r=e^{-t}$, $dr=-e^{-t}dt$, $dt=-e^tdr = -r^{-1}dr$. Which $t=0\implies r=e^0=1$, and $\lim_{t\rightarrow\infty}e^{-t}=\lim_{t\rightarrow\infty}r=0$. So, the integral can be rewrite as:
    $$\int_{0}^{\infty}(1-e^{-t})^{\alpha-1}(e^{-t})^\beta dt=\int_{1}^{0}(1-r)^{\alpha-1}r^{\beta}\cdot (-r^{-1})dr = \int_{0}^{1}(1-r)^{\alpha-1}r^{\beta-1}dr = B(\alpha,\beta)$$
    Hence, we can conclude the following:
    $$\int_{0}^{\infty}\frac{u^{\alpha-1}}{(1+u)^{\alpha+\beta}}du=\int_{0}^{\infty}(1-e^{-t})^{\alpha-1}(e^{-t})^\beta dt=B(\alpha,\beta)$$
\end{itemize}

\hfil

\hfil

\section*{2}
\begin{myBox}[]{}
    \begin{question}
        Stein and Shakarchi Chap. 6 Exercise 9:

        The hypergeometric series $F(\alpha,\beta,\gamma; z)$ was defined as 
        $$F(\alpha,\beta,\gamma;z)=1+\sum_{n=1}^{\infty}\frac{\alpha(\alpha+1)...(\alpha+n-1)\cdot \beta(\beta+1)...(\beta+n-1)}{n!\cdot \gamma(\gamma+1)...(\gamma+n-1)}z^n$$
        Here $\alpha>0,\beta>0,\gamma>\beta$, and $|z|<1$. Show that
        $$F(\alpha,\beta,\gamma;z)=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)}\int_{0}^{1}t^{\beta-1}(1-t)^{\gamma-\beta-1}(1-zt)^{-\alpha}dt$$
        Show as a result that the hypergeometric function, initially defined by a power series convergent in the unit disc, can be continued analytically to the complex plane slit along the half-line $[1,\infty)$.
    \end{question}
\end{myBox}

\textbf{Pf:}

\textbf{Properties of Gamma function:}

First, we can use induction to verity that given $z\in \mathbb{C}\setminus\{0,-1,-2,...\}$, all $n\in\mathbb{N}$ satisfies $\Gamma(z+n)=(z+n-1)...(z+1)z\Gamma(z)$. 

For base case $n=1$, by the identity of gamma function, $\Gamma(z+1)=z\Gamma(z)$, so the formula is true.

Then, suppose for given $n\in\mathbb{N}$, we have $\Gamma(z+n)=(z+n-1)...(z+1)z\Gamma(z)$, which for $(z+n+1)$, it satisfies:
$$\Gamma(z+n+1)=(z+n)\Gamma(z+n)=(z+n)(z+n-1)...(z+1)z\Gamma(z)$$
Hence, this completes the induction.

So, for all $n\in\mathbb{N}$, we also have the following identity:
$$(z+n-1)...(z+1)z = \frac{\Gamma(z+n)}{\Gamma(z)}$$

By this property, we can rewrite the hypergeometric series as follow:
$$F(\alpha,\beta,\gamma;z)=1+\sum_{n=1}^{\infty}\frac{\alpha(\alpha+1)...(\alpha+n-1)\cdot \beta(\beta+1)...(\beta+n-1)}{n!\cdot \gamma(\gamma+1)...(\gamma+n-1)}z^n $$
$$= 1+\sum_{n=1}^{\infty}\frac{(\Gamma(\alpha+n)/\Gamma(\alpha))(\Gamma(\beta+n)/\Gamma(\beta))}{n!\cdot (\Gamma(\gamma+n)/\Gamma(\gamma))}z^n = 1+\frac{\Gamma(\gamma)}{\Gamma(\alpha)\Gamma(\beta)}\sum_{n=1}^{\infty}\frac{\Gamma(\alpha+n)\Gamma(\beta+n)}{n!\cdot \Gamma(\gamma+n)}z^n$$

\hfil

\textbf{Power series of $(1-\zeta)^{-\alpha}$:}

Given $f(\zeta)=(1-\zeta)^{-\alpha}$, it is analytic within the disk $|\zeta|<1$. Then, consider its derivatives at $\zeta=0$, we get:
$$\frac{d}{d\zeta}(1-\zeta)^{-\alpha}=\alpha(1-\zeta)^{-\alpha-1}$$
$$\forall n\in\mathbb{N},\ \frac{d^n}{d\zeta^n}(1-\zeta)^{-\alpha}=(\alpha+n-1)...(\alpha+1)\alpha(1-\zeta)^{-\alpha-n}=\frac{\Gamma(\alpha+n)}{\Gamma(\alpha)}(1-\zeta)^{-\alpha-n}$$
So, $f^{(n)}(0)=\frac{\Gamma(\alpha+n)}{\Gamma(\alpha)}$. Which, the power series about $\zeta=0$ is:
$$f(\zeta)=\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}\zeta^n = \sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!\cdot\Gamma(\alpha)}\zeta^n$$
And, this power series agrees with $f$ in the disk $|\zeta|<1$.

\hfil

\textbf{The Integral:}

Since the power series above converges uniformly for any compact region within the unit disk $|\zeta|<1$, while the integral of the function with $(1-zt)^{-\alpha}$ being defined with $|z|<1$, $t\in (0,1)$, hence the function is integrated over a region that can be covered by a compact set (choose closed disk with radius $|\zeta|\leq R<1$, where $|z|<R$, then for all $t\in (0,1)$, $|zt|\leq |z|<R$, which is in the closed disk $|\zeta|\leq R$).

As the power series converges uniformly on this closed disk, integral and summation in fact commutes, hence the integral mentioned in the question can be represented as:
$$\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)}\int_{0}^{1}t^{\beta-1}(1-t)^{\gamma-\beta-1}(1-zt)^{-\alpha}dt = \frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)}\int_{0}^{1}t^{\beta-1}(1-t)^{\gamma-\beta-1}\left(\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!\cdot\Gamma(\alpha)}(zt)^n\right)dt$$
$$=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!}z^n\int_{0}^{1}t^{\beta+n-1}(1-t)^{\gamma-\beta-1}dt$$
With the identity verified in \textbf{Question 1}, we know the following:
$$\forall \alpha,\beta\in\mathbb{C},\ Re(\alpha),Re(\beta)>0,\quad B(\alpha,\beta)=\int_{0}^{1}(1-t)^{\alpha-1}t^{\beta-1}dt=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$$
Hence, the above form of integral becomes:
$$\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!}z^n\int_{0}^{1}t^{\beta+n-1}(1-t)^{\gamma-\beta-1}dt$$
$$=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!}z^n\cdot B(\gamma-\beta, \beta+n)$$
$$=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!}z^n\cdot\frac{\Gamma(\gamma-\beta)\Gamma(\beta+n)}{\Gamma(\gamma+n)}$$
$$=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)\Gamma(\beta+n)}{n!\Gamma(\gamma+n)}z^n = \frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\alpha)}\cdot\frac{\Gamma(\alpha+0)\Gamma(\beta+0)}{0!\Gamma(\gamma+0)}+\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\alpha)}\sum_{n=1}^{\infty}\frac{\Gamma(\alpha+n)\Gamma(\beta+n)}{n!\Gamma(\gamma+n)}z^n$$
$$=1+\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\alpha)}\sum_{n=1}^{\infty}\frac{\Gamma(\alpha+n)\Gamma(\beta+n)}{n!\Gamma(\gamma+n)}z^n$$
Hence, we can conclude the following:
$$\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)}\int_{0}^{1}t^{\beta-1}(1-t)^{\gamma-\beta-1}(1-zt)^{-\alpha}dt$$
$$=\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\gamma-\beta)\Gamma(\alpha)}\sum_{n=0}^{\infty}\frac{\Gamma(\alpha+n)}{n!}z^n\int_{0}^{1}t^{\beta+n-1}(1-t)^{\gamma-\beta-1}dt$$
$$=1+\frac{\Gamma(\gamma)}{\Gamma(\beta)\Gamma(\alpha)}\sum_{n=1}^{\infty}\frac{\Gamma(\alpha+n)\Gamma(\beta+n)}{n!\Gamma(\gamma+n)}z^n = F(\alpha,\beta,\gamma;z)$$
The identity proposed in the question is showned above.

\hfil

\textbf{Analytic Continuation:}

For all $z\in\mathbb{C}\setminus[1,\infty)$ and all $t\in (0,1)$, then since $z\notin [1,\infty)$, then $tz\notin [1,\infty)$ (since if $tz\in [1,\infty)$, $z\in [1/t,\infty)\subseteq [1,\infty)$, which is a contradiction), hence $(1-tz)\notin (-\infty,0]$.
So, if define a $\log(z)$ to have a branch cut on $(-\infty,0]$, then $\log(1-tz)$ is well-defined and analytic.

Which, on this new domain, the following function is defined, and analytic:
$$\bar{F}(\alpha,\beta,\gamma;z)=\int_{0}^{1}t^{\beta-1}(1-t)^{\gamma-\beta-1}e^{-\alpha\log(1-zt)}dt$$
Which, on the unit disk $|z|<1$, the above function agrees with the hypergeometric functions (since for $t\in (0,1)$ and $|z|<1$, $e^{-\alpha\log(1-zt)}=(1-zt)^{-\alpha}$). Hence, $\bar{F}$ is an analytic continuation of the hypergeometric series on the domain $\mathbb{C}\setminus[1,\infty)$.

\break

\section*{3}
\begin{myBox}[]{}
    \begin{question}
        Stein and Shakarchi Chap. 6 Exercise 13:

        Prove that
        $$\frac{d^2}{ds^2}(\log(\Gamma(s)))=\sum_{n=0}^{\infty}\frac{1}{(s+n)^2}$$
        whenever $s$ is a positive number. Show that if the left-hand side is interpreted
        as $(\Gamma'/\Gamma)'$, then the above formula also holds for all complex numbers $s$ with
        $s\neq 0,-1,-2,...$
    \end{question}
\end{myBox}

\textbf{Pf:}

We'll directly prove the case for viewing it as $\Gamma'/\Gamma$ (which applies to the case for positive real inputs).
First, recall the following characterization of $\Gamma$:
$$\forall z\in\mathbb{C},\quad \frac{1}{\Gamma(z)}=G(z)=ze^{\gamma z}H(z),\quad H(z)=\prod_{n=1}^{\infty}\left(1+\frac{z}{n}\right)e^{-z/n}$$
(Note: $\gamma$ is the Euler-Mascheroni Constant).

Which, the derivative of $1/\Gamma(z)$ given as $-\frac{\Gamma'(z)}{(\Gamma(z))^2}$, while the derivative of $G(z)$ is given as follow:
$$G'(z)=\left(e^{\gamma z}+\gamma ze^{\gamma z}\right)H(z)+ze^{\gamma z}H'(z) = \frac{1}{z}\cdot ze^{\gamma z}H(z)+\gamma\cdot ze^{\gamma z}H(z)+ze^{\gamma z}H'(z)$$
$$ = \left(\frac{1}{z}+\gamma\right)G(z)+ze^{\gamma z}H'(z)$$
So, to find the derivative of $1/\Gamma$, the only thing left is finding a precise formula for $H'(z)$.

\hfil

\textbf{Expression of $H'(z)$:}

For all $z\in\mathbb{C}$, choose $N\in\mathbb{N}$, such that for all $n\in\mathbb{N}$, $n\geq N$ implies $\left|\frac{z}{n}\right|\leq \frac{1}{2}$ (in other words, we're working in the disk $|z|\leq \frac{N}{2}$, which is compact). 
Then, we can define a single-valued branch for $\log(1+\zeta)$ for $|\zeta|<1$.
Which, by grouping the components of the product in $H(z)$, we get the following:
$$H(z)=\prod_{n=1}^{\infty}\left(1+\frac{z}{n}\right)e^{-z/n}=\left(\prod_{n=1}^{N}\left(1+\frac{z}{n}\right)e^{-z/n}\right)\cdot\left(\prod_{n=N+1}^{\infty}\left(1+\frac{z}{n}\right)e^{-z/n}\right)$$
$$=\left(\prod_{n=1}^{N}\left(1+\frac{z}{n}\right)\right)\cdot \left(\prod_{n=1}^{N}e^{-z/n}\right)\cdot\left(\prod_{n=N+1}^{\infty}\exp\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
$$=\left(\prod_{n=1}^{N}\left(1+\frac{z}{n}\right)\right)\cdot \exp\left(\sum_{n=1}^{N}-\frac{z}{n}\right)\cdot\exp\left(\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
$$=\left(\prod_{n=1}^{N}\left(1+\frac{z}{n}\right)\right)\cdot\exp\left(-\sum_{n=1}^{N}\frac{z}{n}+\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
Before continuing, we need to argue why the infinite series of function in the above exponent converges normally in the disk:
Since $\left|\frac{z}{n}\right|\leq \frac{1}{2}$ for all $n\geq N$, then the power series of $\log(1+\frac{z}{n})$ is $-\sum_{k=1}^{\infty}\frac{(-1)^k}{k}\left(\frac{z}{n}\right)^k$. Then, each index $n\geq N$ satisfies the following:
$$\left|\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right|=\left|-\sum_{k=1}^{\infty}\frac{(-1)^k}{k}\left(\frac{z}{n}\right)^k-\frac{z}{n}\right| = \left|\sum_{k=2}^{\infty}\frac{(-1)^k}{k}\left(\frac{z}{n}\right)^k\right| \leq \sum_{k=2}^{\infty}\frac{1}{k}\left|\frac{z}{n}\right|^k$$
$$\leq \sum_{k=2}^{\infty}\left|\frac{z}{n}\right|^k\leq \left|\frac{z}{n}\right|^2\sum_{k=2}^{\infty}\left|\frac{z}{n}\right|^{k-2} = \left|\frac{z}{n}\right|^2\sum_{k=0}^{\infty}\left|\frac{z}{n}\right|^k\leq \left|\frac{z}{n}\right|^2\sum_{k=0}^{\infty}\left(\frac{1}{2}\right)^k = 2\left|\frac{z}{n}\right|^2$$
With the assumption that we're working over the disk $|z|\leq \frac{N}{2}$, the above bound can be simplified as:
$$\left|\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right|\leq 2\left|\frac{z}{n}\right|^2 \leq 2\left(\frac{N}{2}\right)^2\cdot\frac{1}{n^2} = \frac{N^2}{2}\cdot\frac{1}{n^2}$$
Hence, the series of function converges normally in the disk because of the following inequality:
$$\sum_{n=N+1}^{\infty}\left|\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right|\leq \sum_{n=N+1}^{\infty}\frac{N^2}{2}\cdot\frac{1}{n^2}<\infty$$
So, it's valid to talk about the way we organize the infinite product in $H(z)$ (and more conveniently, the above infinite series can be differentiated term by term).

\hfil

Now, define the two functions $A(z),B(z)$ on the disk $|z|\leq \frac{N}{2}$ as follow:
$$A(z)=\prod_{n=1}^{N}\left(1+\frac{z}{n}\right),\quad B(z)=\exp\left(-\sum_{n=1}^{N}\frac{z}{n}+\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
Then, the function $H=AB$, hence the derivative is given by $H'=A'B+B'A$.

For $A'(z)$, it is expressed as follow:
$$A'(z)=\sum_{n=1}^{N}\left(\frac{d}{dz}\left(1+\frac{z}{n}\right)\right)\cdot \left(\prod_{k=1,\ k\neq n}^{N}\left(1+\frac{z}{k}\right)\right)=\sum_{n=1}^{N}\frac{1}{n}\cdot\left(\prod_{k=1,\ k\neq n}^{N}\left(1+\frac{z}{k}\right)\right)$$
$$=\sum_{n=1}^{N}\frac{1}{n}\cdot\frac{1}{1+\frac{z}{n}}\cdot\left(\prod_{k=1}^{N}\left(1+\frac{z}{k}\right)\right) = \sum_{n=1}^{N}\frac{1}{z+n}\cdot A(z)$$
For $B'(z)$, it is expressed as follow:
$$B'(z)=\frac{d}{dz}\exp\left(-\sum_{n=1}^{N}\frac{z}{n}+\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
$$=\exp\left(-\sum_{n=1}^{N}\frac{z}{n}+\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)\cdot \frac{d}{dz}\left(-\sum_{n=1}^{N}\frac{z}{n}+\sum_{n=N+1}^{\infty}\left(\log\left(1+\frac{z}{n}\right)-\frac{z}{n}\right)\right)$$
$$= B(z)\left(-\sum_{n=1}^{N}\frac{1}{n}+\sum_{n=N+1}^{\infty}\left(\frac{1/n}{1+z/n}-\frac{1}{n}\right)\right) =B(z)\left(-\sum_{n=1}^{N}\frac{1}{n}+\sum_{n=N+1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$
Then, $H'(z)$ is then given by:
$$H'(z)=A'B+B'A = \left(\sum_{n=1}^{N}\frac{1}{z+n}\right)\cdot A(z)\cdot B(z)+B(z)\left(-\sum_{n=1}^{N}\frac{1}{n}+\sum_{n=N+1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)\cdot A(z)$$
$$=A(z)B(z)\cdot\left(\sum_{n=1}^{N}\left(\frac{1}{z+n}-\frac{1}{n}\right)+\sum_{n=N+1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)= H(z)\left(\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$

\hfil

\textbf{Expression of $\Gamma'/\Gamma$ and its derivative:}

Now, for all $z\in\mathbb{C}$, plug $H'(z)$ back into the original expression of derivative, we get the following:
$$\frac{-\Gamma'(z)}{(\Gamma(z))^2}=\left(\frac{1}{\Gamma(z)}\right)'=G'(z)=\left(\frac{1}{z}+\gamma\right)G(z)+ze^{\gamma z}H'(z)$$
$$=\left(\frac{1}{z}+\gamma\right)G(z)+ze^{\gamma z}H(z)\left(\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$
$$=\left(\gamma+\frac{1}{z}\right)G(z)+G(z)\left(\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$
$$=G(z)\left(\gamma+\frac{1}{z}+\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$
Then, since $G(z)=\frac{1}{\Gamma(z)}$, then for all $z\in\mathbb{C}\setminus S$, with $S=\{0,-1,-2,...\}$, we get:
$$\frac{\Gamma'(z)}{\Gamma(z)}=\frac{-\Gamma'(z)}{(\Gamma(z))^2}\cdot(-\Gamma(z)) = (-\Gamma(z))\cdot G(z)\left(\gamma+\frac{1}{z}+\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)$$
$$ = -\gamma-\frac{1}{z}-\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)$$
Finally, the derivative $(\Gamma'/\Gamma)'$ is given as follow:
$$\left(\frac{\Gamma'(z)}{\Gamma(z)}\right)'=\frac{d}{dz}\left(-\gamma-\frac{1}{z}-\sum_{n=1}^{\infty}\left(\frac{1}{z+n}-\frac{1}{n}\right)\right)=\frac{1}{z^2}+\sum_{n=1}^{\infty}\frac{1}{(z+n)^2}=\sum_{n=0}^{\infty}\frac{1}{(z+n)^2}$$
Then, the above equation is the desired generalization for the problem.

\hfil

\textbf{Special Case for real positive inputs:}

If restrict the domain to $\mathbb{R}_{>0}$, the function $\log(\Gamma(s))$ is well-defined, and its derivative is given as:
$$\frac{d}{ds}\log(\Gamma(s))=\frac{\Gamma'(s)}{\Gamma(s)},\quad \frac{d^2}{ds^2}\log(\Gamma(s))=\frac{d}{ds}\left(\frac{\Gamma'(s)}{\Gamma(s)}\right)=\sum_{n=0}^{\infty}\frac{1}{(s+n)^2}$$
Which, this finishes the special case for all $s>0$.

\break

\section*{4}
\begin{myBox}[]{}
    \begin{question}
        Stein and Shakarchi Chap. 6 Exercise 14:

        This exercise gives an asymptotic formula for $\log n!$.
        \begin{itemize}
            \item[(a)] Show that
            $$\frac{d}{dx}\int_{x}^{x+1}\log\Gamma(t)dt = \log x,\quad x>0$$
            and as a result 
            $$\int_{x}^{x+1}\log\Gamma(t)dt = x\log x-x+c$$
            \item[(b)] Show as a consequence that $\log\Gamma(n)\approx n\log n$ as $n\rightarrow\infty$. 
            In fact, prove that $\log\Gamma(n)\approx n\log n+O(n)$ as $n\rightarrow\infty$. 

            [Hint: Use the fact that $\Gamma(x)$ is monotonically increasing for all large $x$.]
        \end{itemize}
    \end{question}
\end{myBox}

\textbf{Pf:}

\begin{itemize}
    \item[(a)] Given the first derivative in the question part (a), since for $x>0$, $\Gamma(x)=\int_{0}^{\infty}t^{x-1}e^{-t}dt>0$, then $\log\Gamma(x)$ is defined and continuous on $\mathbb{R}>0$. Then, by Fundamental Theorem of Calculus, we get:
    $$\frac{d}{dx}\int_{x}^{x+1}\log\Gamma(t)dt = \log\Gamma(x+1)-\log\Gamma(x) = \log(x\Gamma(x))-\log\Gamma(x)$$
    $$= \log(x)+\log\Gamma(x)-\log\Gamma(x)=\log(x)$$
    Hence, since the antiderivative of $\log(x)$ is $x\log(x)-x+c$ for arbitrary $c\in\mathbb{R}$, then we get:
    $$\int_{x}^{x+1}\log\Gamma(t)dt = x\log(x)-x+c$$

    \hfil

    \item[(b)] For all $x>0$ that's sufficiently large, $\Gamma(x)$ is monotonically increasing, hence for $t\in[x,x+1]$, $\log\Gamma(x+1)\geq\log\Gamma(t)\geq \log\Gamma(x)$. Then, for all $n\in\mathbb{N}$ that's sufficiently large (in particular, $n>>1$), we have:
    $$n\log(n)-n+c=\int_{n}^{n+1}\log\Gamma(t)dt\geq \int_{n}^{n+1}\log\Gamma(n)dt = \log\Gamma(n)$$
    $$(n-1)\log(n-1)-(n-1)+c=\int_{n-1}^{(n-1)+1}\log\Gamma(t)dt \leq \int_{n-1}^{n}\log\Gamma(n)dt=\log\Gamma(n)$$
    (Note: The constant $c\in\mathbb{R}$ can be chosen to satisfy $n\log(n)-n+c=\int_{n}^{n+1}\log\Gamma(t)dt$).

    Then, for the second inequality, after doing some modification to the expression $(n-1)\log(n-1)-(n-1)+c$, we get:
    $$n\log(n-1)-\log(n-1)-n+1+c = n\log(n)\cdot\frac{\log(n-1)}{\log(n)}-n-\log(n-1)+c$$
    As $n\rightarrow\infty$, $\frac{\log(n-1)}{\log(n)}\rightarrow 1$, then the actual inequality then can be approximated as:
    $$n\log(n)-n-\log(n-1)+c\approx (n-1)\log(n-1)-(n-1)+c\leq \log\Gamma(n)\leq n\log(n)-n+c$$
    Which, for function $n+\log(n-1)-c$ and $n-c$, both functions are dominated by $n$ as $n\rightarrow \infty$ (which can be approximated with $O(n)$), hence, the function is given as:
    $$n\log(n)-(n+\log(n-1)-c)\leq \log\Gamma(n)\leq n\log(n)-(n-c)$$
    $$\log\Gamma(n)\approx n\log(n)+O(n)$$
\end{itemize}

\hfil

\hfil

\section*{5}
\begin{myBox}[]{}
    \begin{question}
        Freitag Chap. IV.2 Exercise 5:

        Let $R=\mathcal{O}(\mathbb{C})$ be the ring of analytic functions in $\mathbb{C}$.
        \begin{itemize}
            \item[(a)] Let $\textbf{a}$ be the set of all entire functions $f$ with the following property.
            There exists a natural number $m$, such that $f$ vanishes at all points of $m\mathbb{Z}=\{0,\pm m,\pm 2m,...\}$.
            show that $\textbf{a}$ is not finitely generated.
            \item[(b)] Which are the irreducible elements in $\mathcal{O}(\mathbb{C})$? Which are the prime elements in $\mathcal{O}(\mathbb{C})$?
            \item[(c)] Which are the inverible elements (i.e. the units) in $\mathcal{O}(\mathbb{C})$?
            \item[(d)] $\mathcal{O}(\mathbb{C})$ is not a UFD, i.e. there exists elements $\neq 0$ in $\mathcal{O}(\mathbb{C})$ which cannot be written as product of finitely many prime elements.
            \item[(e)] Any finitely generated ideal in $\mathcal{O}(\mathbb{C})$ with $Af+Bg=1$.
            
            (For the proof, it can be used that for any discrete subset $S\subset\mathbb{C}$, and for
            any function $h_0:S\rightarrow\mathbb{C}$ there exists an entire function $h:\mathbb{C}\rightarrow\mathbb{C}$ which
            equals $h_0$ on $S$. In fact, more is true, one can even prescribe for any $s\in S$
            finitely many Taylor coefficients).
        \end{itemize}
    \end{question}
\end{myBox}

\textbf{Pf:}

\begin{itemize}
    \item[(a)] Given $\textbf{a}$ the ideal described in the problem, we'll prove by contradiction that it's not finitely generated.
    Suppose the contrary that it is finitely generated, then there exists $f_1,...,f_n\in\textbf{a}$, with $\textbf{a}=(f_1,...,f_n)$.

    For each index $i\in\{1,...,n\}$, there exists $m_i\in\mathbb{N}$, such that $f_i$ yields $0$ for all points in $m_i\mathbb{Z}$.
    Then, take $m=lcm(m_1,...,m_n)$, for all $k\in m\mathbb{Z}$, since each index $i$ satisfies $m_i\mid m$, then $m_i\mid k$, showing that $k\in m_i\mathbb{Z}$.
    Hence, $f_i(k)=0$.

    Since all functions $f\in\textbf{a} = A_1f_1+...+A_nf_n$ for some $A_1,...,A_n\in\mathcal{O}(\mathbb{C})$, and every $k\in m\mathbb{Z}$ satisfies $f_i(k)=0$, regardless of the index $i$,
     $f(k)=0$, hence all $f$ should vanish on the collection $m\mathbb{Z}$.

    Yet, here is a counterexample: Consider the function $\sin(\pi z/(2m))\in\mathcal{O}(\mathbb{C})$: For all $k\in 2m\mathbb{Z}$, since $k=2ml$ for some $l\in\mathbb{Z}$,
    then $\sin(\pi k/2m)=\sin(\pi\cdot 2ml/(2m))=\sin(\pi l)=0$, so $\sin(\pi z/(2m))\in \textbf{a}$.
    But if we evaluate $m\in m\mathbb{Z}$, we get $\sin(\pi\cdot m/(2m))=\sin(\pi/2)=1$, which such function is contained in $\textbf{a}$, while not vanishing on all points of $m\mathbb{Z}$,
    which contradicts the statement proven before. 

    Hence, the assumption is false, $\textbf{a}$ is not finitely generated.

    \hfil

    \item[(b)] \textbf{Irreducible elements:}
    
    Suppose $f\in\mathcal{O}(\mathbb{C})$ is irreducible, then it's not invertible, which an element is invertible in $\mathcal{O}(\mathbb{C})$ iff it doesn't vanish at all points in $\mathbb{C}$ (will be proven in \textbf{Part (c)}).
    Hence, for $f$ to be non-invertible, $f(a)=0$ for some $a\in\mathbb{C}$.

    Furthermore, if $f$ is irreducible, it cannot have more than one zero, including multiplicity: Suppose $f$ vanishes at $a,b\in\mathbb{C}$ (here, either $b=a$ when $a$ has multiplicity more than $1$, or $b\neq a$),
    then $f(z)=(z-a)(z-b)f_2(z)$ for some $f_2\in\mathcal{O}(\mathbb{C})$. Hence, since both $(z-a)$ and $(z-b)f_2(z)$ have zeros in $\mathbb{C}$, which are not invertible, $f$ is a product of two non-invertible elements, hence it's not irreducible.
    So, for $f$ to be irreducible, it must have a unique zero with multiplicity $1$.

    Lastly, if $f$ has only one zero and with multiplicity $1$, it must be irreducible: Suppose it's not irreducible, there exists noninvertible $g,h\in\mathcal{O}(\mathbb{C})$, with $f=gh$. But, since $g,h$ are not invertible, there exists $a,b\in\mathbb{C}$,
    with $g(a)=0$, and $h(b)=0$, hence $g(z)=(z-a)g_1(z)$, $h(z)=(z-b)h_1(z)$ for some $g_1,h_1\in\mathcal{O}(\mathbb{C})$, or $f(z)=(z-a)g_1(z)(z-b)h_1(z)$.
    However, this implies $f$ have multiple zeros (counting the case with multiplicity $>1$), which is a contradiction.
    Therefore, $f$ must be irreducible.

    With the above statements, we can conclude that $f$ is irreducible iff it has precisely one zero, and with multiplicity $1$. So, all irreducible elements are in the form $(z-a)h(z)$, where $h(z)\in\mathcal{O}(\mathbb{C})$ is invertible, which vanishess nowhere on $\mathbb{C}$.
    (More precisely, all irreducible element is some associates of $(z-a)$ for some $a\in\mathbb{C}$).

    \hfil

    \textbf{Prime elements:}

    Since all prime elements are irreducible, they must be a subset of the irreducible elements; in this case, we can prove that all irreducible elements are in fact prime.
    
    For all irreducible element in $\mathcal{O}(\mathbb{C})$, it is some associates of $(z-a)$ for some $a\in\mathbb{C}$.
    Now, suppose $f,g\in\mathcal{O}(\mathbb{C})$ satisfies $(z-a)\mid f(z)g(z)$, then $f(z)g(z)=(z-a)h(z)$ for some $h\in\mathcal{O}(\mathbb{C})$.

    Then, since $f(a)g(a)=(a-a)h(a)=0$, then since $\mathbb{C}$ is a field (in particular, an Integral Domain), either $f(a)=0$ or $g(a)=0$.
    WLOG, suppose $f(a)=0$, that implies $f(z)=(z-a)f_1(z)$ for some $f_1(z)\in\mathcal{O}(\mathbb{C})$, hence $(z-a)\mid f(z)$. (If $g(a)=0$ instead, swap $f(z)$ and $g(z)$ then the statement still holds).

    Since $(z-a)\mid f(z)g(z)$ implies $(z-a)\mid f(z)$ or $(z-a)\mid g(z)$, then $(z-a)$ is in fact prime, which proves that all irreducible elements are prime elements also in $\mathcal{O}(\mathbb{C})$.

    \hfil

    \item[(c)] We'll prove that $f\in\mathcal{O}(\mathbb{C})$ is invertible, iff it doesn't vanish at all points in $\mathbb{C}$.
    \begin{itemize}
        \item[$\implies$:] Suppose $f$ is invertible, then there exists $h\in\mathcal{O}(\mathbb{C})$, where $f(z)h(z)\equiv 1$. Hence, for all $a\in\mathbb{C}$, since $f(a)g(a)=1$, then $f(a)\neq 0$, showing that $f$ doesn't vanish for all $a\in\mathbb{C}$.
        \item[$\impliedby$:] Suppose $f$ doesn't vanish for all $a\in\mathbb{C}$, then $\frac{1}{f(z)}$ is well-defined and analytic on the whole $\mathbb{C}$, and for all $a\in\mathbb{C}$, $f(a)\cdot\frac{1}{f(a)}=1$, hence $f(z)\cdot\frac{1}{f(z)}\equiv 1$, showing that $f$ is invertible.
    \end{itemize}

    \hfil

    \item[(d)] Consider the following function $\sin(\pi z)\in\mathcal{O}(\mathbb{C})$, we'll prove by contradiction that the above function can't be factored into finitely many prime numbers.
    
    Suppose it can, there exists prime elements $f_1,...,f_n\in\mathcal{O}(\mathbb{C})$, such that $\sin(\pi z)=\prod_{i=1}^{n}f_i(z)$.
    Since in \textbf{Part (b)}, we've proven that each prime element (which is irreducible) has precisely one zero with multiplicity $1$, then for each index $i\in\{1,...,n\}$,
    there exists unique $a_i\in\mathbb{C}$, with $f_i(a_i)=0$, which $f_i(z)=(z-a_i)\bar{f}_i(z)$, where $\bar{f}_i\in\mathbb{O}(\mathbb{C})$ has no zeroes, hence it is invertible.

    So, $\sin(\pi z)$ can be expressed as:
    $$\sin(\pi z)=\prod_{i=1}^{n}f_i(z) = \left(\prod_{i=1}^{n}(z-a_i)\right)\left(\prod_{i=1}^{n}\bar{f}_i(z)\right)$$
    Where, the second product is formed by invertible elements, hence it is also invertible (which has no zeros). Then, it implies that $\sin(\pi z)$ has zeros $a_1,...,a_n$, only $n$ zeros (counting multiplicity), which contradicts the fact that $\sin(\pi z)$ vanishes at all points in $\mathbb{Z}$.

    So, the above function is an example that can't be factored into finitely many prime elements, showing that $\mathcal{O}(\mathbb{C})$ is not a UFD.

    \hfil

    \item[(e)] To show that any finitely generated ideal is principal, we'll show some statements in the following order:

    \begin{proposition}
        \textbf{Two nonero functions with no common zeros generate a unit ideal.}
    \end{proposition}

    Suppose nonzero $f,g\in\mathcal{O}(\mathbb{C})$ have no common zeros. We can first assume both $f,g$ has zeros (if one of them has no zeros, WLOG, say $f$ has no zeros, then $\frac{1}{f}\cdot f+0\cdot g \equiv 1\in (f,g)$, so $(f,g)$ is a unit ideal).
    Which, the collection of zeros for $f$ and $g$ must be discrete, since nonconstant analytic function must have isolated zeros.

    Let the discrete subsets $S_f=\{f_i\ |\ i\in I\},\ S_g=\{g_j\ |\ j\in J\}$ be the collections of zeros of $f$ and $g$ respectively (which by assumption, $S_f\cap S_g=\emptyset$). Now, for each $i\in I, j\in J$, let $n_i,m_j\in\mathbb{N}$ be the corresponding multiplicity of $f_i,g_j$ respectively.
    Our goal is to construct two functions $A,B\in\mathcal{O}(\mathbb{C})$, with $Af+Bg\equiv 1$.

    \hfil

    Since both $S_f,S_g$ are discrete, $S_f\sqcup S_g$ is also discrete (since for all $z\in\mathbb{C}$, there exists radius $r_1,r_2>0$, with $B_{r_1}(z)\setminus\{z\}\cap S_f=B_{r_2}(z)\setminus\{z\}\cap S_g=\emptyset$, then choose $r=\min\{r_1,r_2\}>0$, $B_r(z)\setminus\{z\}\cap S_f=B_r(z)\setminus\{z\}\cap S_g=\emptyset$, showing that $S_f\sqcup S_g$ has no limit points).
    Then, by the property given in the question part (e), take a function $h_0:S_f\sqcup S_g\rightarrow\mathbb{C}$ by $h_0(f_i)=0$ and $h_0(g_j)-1=0$ for all $i\in I,j\in J$ (which $h_0$ is well-defined, since $S_f,S_g$ are disjoint), we know there exists an entire analytic function $h\in\mathcal{O}(\mathbb{C})$, such that $h|_{S_f\sqcup S_g}=h_0$, and each $f_i\in S_f$ has multiplicity $n_i$ for function $h(z)$, while each $g_j\in S_g$ has multiplicity $m_j$ for function $h(z)-1$.

    \hfil

    Now, consider $B(z)=\frac{1-h(z)}{g(z)}$, and $A(z)=\frac{h(z)}{f(z)}$: 

    Since $B$ is only not well-defined at the zeros of $g$, which just needs to resolve the singularity at all points of $S_g$. However, for all $g_j\in S_g$, it's a zero with multiplicity $m_j$ for $g$, and by the above construction, it's a zero with multiplicity $m_j$ also for the function $h(z)-1$.
    Hence, $h(z)-1=(z-g_j)^{m_j}\bar{h}(z)$, and $g(z)=(z-g_j)^{m_j}\bar{g}(z)$, for $\bar{h},\bar{g}\in\mathcal{O}(\mathbb{C})$ that are not vanishing at $g_j$. Then, consider the following limit:
    $$\lim_{z\rightarrow g_j}(z-g_j)B(z)=\lim_{z\rightarrow g_j}(z-g_j)\cdot\frac{1-h(z)}{g(z)}=\lim_{z\rightarrow g_j}(z-g_j)\cdot\frac{-(z-g_j)^{m_j}\bar{h}(z)}{(z-g_j)^{m_j}\bar{g}(z)}$$
    $$=\lim_{z\rightarrow g_j}-(z-g_j)\cdot\frac{\bar{h}(z)}{\bar{g}(z)}=0$$
    Hence, the above limit provides $0$, implies that $B(z)$ has a removable singularity at $g_j$. So, $B(z)$ can be extended analytically onto the whole $\mathbb{C}$.

    On the other hand, $A(z)$ is only not well-defined at the zeros of $f$, which just needs to resolve the singularity at all points of $S_f$. Again, for all $f_i\in S_f$, it's a zero with multiplicity $n_i$ for $f$, and again by the construction of $h$, it's a zero with multiplicity $n_i$ also for function $h$.
    Then, $h(z)=(z-f_i)^{n_i}\tilde{h}(z)$, and $f(z)=(z-f_i)^{n_i}\tilde{f}(z)$ for $\tilde{h},\tilde{f}\in\mathcal{O}(\mathbb{C})$ that are not vanishing at $f_i$. Hence, the following limit provides:
    $$\lim_{z\rightarrow f_i}(z-f_i)A(z)=\lim_{z\rightarrow f_i}(z-f_i)\cdot\frac{h(z)}{f(z)}=\lim_{z\rightarrow f_i}(z-f_i)\cdot\frac{(z-f_i)^{n_i}\tilde{h}(z)}{(z-f_i)^{n_i}\tilde{f}(z)}$$
    $$=\lim_{z\rightarrow f_i}(z-f_i)\cdot\frac{\tilde{h}(z)}{\tilde{f}(z)}=0$$
    Hence, the above limit is $0$ implies that $A(z)$ has a removable singularity at $f_i$, showing that $A(z)$ can be extended analytically onto the whole $\mathbb{C}$.

    Which, if evaluate $Af+Bg$, we get:
    $$A(z)f(z)+B(z)g(z)=\frac{h(z)}{f(z)}f(z)+\frac{1-h(z)}{g(z)}g(z)=h(z)+(1-h(z))\equiv 1$$
    Hence, $1\in (f,g)$, showing that $f,g$ generates a unit ideal.

    \hfil

    \begin{proposition}
        \textbf{Any two nonzero functions generate a principal ideal.}
    \end{proposition}

    Given arbitrary nonzero $f,g\in\mathcal{O}(\mathbb{C})$, which we can assume they share some common zeros (since we've shown above, that two nonzero functions with no common zero generate a unit ideal).

    Let discrete subset $S_h=\{h_i\ |\ i\in I\}$ denotes the common zeros of $f,g$. For each $i\in I$, let $n_i,m_i\in\mathbb{N}$ be the multiplicity of $h_i$ as a zero of $f$ and $g$ respectively, then $f(z)=(z-h_i)^{n_i}f_i(z),\ g(z)=(z-h_i)^{m_i}g_i(z)$ for $f_i,g_i\in\mathcal{O}(\mathbb{C})$ that are not vanishing at $h_i$. Which, define $g_i=\min\{n_i,m_i\}$ for each index $i\in I$,
    and construct a Weierstrass Product function $h(z)\in\mathcal{O}(\mathbb{C})$, such that $h(h_i)=0$, and $h_i$ has multiplicity $g_i$ for all $i\in I$ (so, $h$ only has zeros on $S_h$).

    Now, consider the function $\frac{f}{h},\ \frac{g}{h}$: They're only not defined on the zeros of $h$ (namely the set $S_h$). Which, for all $i\in I$, we know $f(z)=(z-h_i)^{n_i}f_i(z)$, and $g(z)=(z-h_i)^{m_i}g_i(z)$;
    also, since $h_i$ is a zero with multiplity $g_i=\min\{m_i,n_i\}$ for $h$, then $h(z)=(z-h_i)^{g_i}\bar{h_i}(z)$ for $\bar{h_i}\in \mathcal{O}(\mathbb{C})$ that's not vanishing at $h_i$.
    Then, evaluate the following two limits, we get:
    $$\lim_{z\rightarrow h_i}(z-h_i)\frac{f(z)}{h(z)}=\lim_{z\rightarrow h_i}(z-h_i)\frac{(z-h_i)^{n_i}f_i(z)}{(z-h_i)^{g_i}\bar{h_i}(z)} = \lim_{z\rightarrow h_i}(z-h_i)^{n_i-g_i+1}\frac{f_i(z)}{\bar{h_i}(z)}=0$$
    $$\lim_{z\rightarrow h_i}(z-h_i)\frac{g(z)}{h(z)}=\lim_{z\rightarrow h_i}(z-h_i)\frac{(z-h_i)^{m_i}g_i(z)}{(z-h_i)^{g_i}\bar{h_i}(z)} = \lim_{z\rightarrow h_i}(z-h_i)^{m_i-g_i+1}\frac{g_i(z)}{\bar{h_i}(z)}=0$$
    (Note: since $n_i,m_i\geq g_i$, then $(n_i-g_i+1),(m_i-g_i+1)\geq 1$).

    Hence, both $\frac{f}{h},\frac{g}{h}$ have removable singularity at $h_i$, showing that both functions can be extended analytically onto $\mathbb{C}$.

    On the other hand, since $g_i=\min\{n_i,m_i\}$, then $g_i=n_i$ or $g_i=m_i$ (WLOG, say $g_i=n_i$), then $\frac{f}{h}$ is given as:
    $$\frac{f(z)}{h(z)}=\frac{(z-h_i)^{n_i}f_i(z)}{(z-h_i)^{g_i}\bar{h_i}(z)} = \frac{f_i(z)}{\bar{h_i}(z)}$$
    Notice that both $f_i,\bar{h_i}$ are not vanishing at $h_i\in S_h$. Hence, $\frac{f}{h}$ doesn't vanish at $h_i$. (Same statement applies to $\frac{g}{h}$ if $g_i=m_i$).

    So, for all $i\in I$, $h_i$ is not vanishing for at least one function in $\frac{f}{h}$ and $\frac{g}{h}$, showing that $\frac{f}{h},\frac{g}{h}$ sharing no common zeros (since the only possible common zeros are the zeros for both $f$ and $g$, and we verified that each common zero for $f,g$ is nonvanishing for one of the functions $\frac{f}{h},\frac{g}{h}$).
    
    Hence, by \textbf{Proposition 1}, $\frac{f}{h},\frac{g}{h}$ generates a unit ideal, there exists $A,B\in\mathcal{O}(\mathbb{C})$ with $A\frac{f}{h}+A\frac{g}{h}=1$, or $h=Af+Bg$.
    Therefore, the ideal $(h)\subseteq(f,g)$, while $f=\frac{f}{h}\cdot h$ and $g=\frac{g}{h}\cdot h$, showing that $f,g\in (h)$, or $(f,g)\subseteq (h)$.
    Hence, $(f,g)=(h)$, showing that $f,g$ generates a principal ideal.

    \hfil

    Finally, with the above statements, we can use induction to prove that \textbf{All finitely generated ideal in $\mathcal{O}(\mathbb{C})$ is principal}.

    For the ideals generated by $n=2$ functions, we've proven that in \textbf{Proposition 2}.

    Now, suppose for given $n\in\mathbb{N}$, any $f_1,...,f_n\in\mathcal{O}(\mathbb{C})$ generates a principal ideal (i.e. there exists $h\in\mathcal{O}(\mathbb{C})$, with $(h)=(f_1,...,f_n)$),
    then for the case $(n+1)$, any $f_1,...,f_n,f_{n+1}\in\mathcal{O}(\mathbb{C})$, since $(f_1,...,f_n)=(h)$ for some $h\in\mathcal{O}(\mathbb{C})$, then $(f_1,...,f_n,f_{n+1})=(h,f_{n+1})$.
    
    Which again by \textbf{Proposition 2}, there exists $\bar{h}\in\mathcal{O}(\mathbb{C})$, with $(h,f_{n+1})=(\bar{h})$, hence this proves that $(f_1,...,f_n,f_{n+1})=(\bar{h})$, the ideal is principal.
    
    This completes the induction, shows that all finitely generated ideal is in fact principal.
\end{itemize}

\end{document}